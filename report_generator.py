import datetime
import json
import re
from config import generator


def generate_report(level, interview_type, evaluation_log):
    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    weak_topics = []  # NEW: List of weak question topics

    # existing candidate_name detection...
    candidate_name = "N/A"
    for entry in evaluation_log:
        answer = entry.get("answer", "")
        matches = re.findall(r'\b[A-Z][a-z]+\b', answer)
        if matches:
            candidate_name = matches[0]
            break

    # existing HR/Technical question separation...
    is_technical = interview_type.lower() == "technical"
    is_hr = interview_type.lower() == "hr"

    hr_questions = [] if is_technical else [q for q in evaluation_log if "behavior" in q.get("question", "").lower() or "team" in q.get("question", "").lower()]
    tech_questions = [] if is_hr else [q for q in evaluation_log if q not in hr_questions]

    def correct_spelling(text):
        corrections = {
            r"\bhtml\b": "HTML",
            r"\bcss\b": "CSS",
            r"\bjavascript\b": "JavaScript",
            r"\breact\b": "React",
            r"\bnode\.js\b": "Node.js",
            r"\bpython\b": "Python",
            r"\bmern\b": "MERN"
        }
        for pattern, repl in corrections.items():
            text = re.sub(pattern, repl, text, flags=re.IGNORECASE)
        return text

    def section_summary(entries, section_name):
        if not entries:
            return f"{section_name}:\nNo questions answered.\n"

        summary_lines = [f"{section_name}:"]
        strengths = set()
        weaknesses = set()
        total_score = 0

        for i, entry in enumerate(entries, 1):
            q = correct_spelling(entry.get("question", "N/A"))
            a = correct_spelling(entry.get("answer", "N/A"))
            relevance = entry.get("relevance", 0)
            technical = entry.get("technical_correctness", 0)
            clarity = entry.get("clarity", 0)
            avg_score = round((relevance + technical + clarity) / 3, 2)
            total_score += avg_score

            comment = entry.get("comment", "") if i > 1 else ""

            summary_lines.append(f"Q{i}: {q}\nA{i}: {a}\n{'Comment: ' + comment if comment else ''}\nScore: {avg_score}/5\n")

            # Strength skills
            if technical >= 4:
                strengths.add("Technical Knowledge")
            if relevance >= 4:
                strengths.add("Answer Relevance")
            if clarity >= 4:
                strengths.add("Communication Clarity")

            # Weak skill areas → Collect weak topics
            if relevance < 3 or technical < 3 or clarity < 3:
                weaknesses.add("Weak Topic")
                weak_topics.append(q)  # ADD weak topic question

        avg_section_score = round(total_score / len(entries), 2)
        summary_lines.append(f"Section Average Score: {avg_section_score}/5")
        summary_lines.append("Strengths: " + (", ".join(strengths) if strengths else "None"))
        summary_lines.append("Weaknesses: " + (", ".join(weaknesses) if weaknesses else "None"))

        return "\n".join(summary_lines)

    try:
        prompt = f"Summarize the candidate's interview performance from this log:\n{json.dumps(evaluation_log, indent=2)}\nHighlight strengths, weaknesses, and engagement concisely."
        overall_summary = generator(prompt, max_tokens=200)
    except Exception:
        overall_summary = "Could not generate AI summary. Please see detailed evaluation below."

    candidate_details = f"""
📄 Final Interview Report (Generated by Chatbot)
1. Candidate Details
Name: {candidate_name}
Interview Mode: {interview_type.capitalize()}
Difficulty Level: {level.capitalize()}
Date & Time: {now}
"""

    interview_summary = f"""
2. Interview Summary
{overall_summary}
Total Questions Answered: {len(evaluation_log)}
"""

    hr_section = section_summary(hr_questions, "3a) HR Questions") if not is_technical else ""
    tech_section = section_summary(tech_questions, "3b) Technical Questions") if not is_hr else ""

    overall_score = round(sum((q.get("relevance", 0) + q.get("technical_correctness", 0) + q.get("clarity", 0)) / 3 for q in evaluation_log) / len(evaluation_log), 2) if evaluation_log else 0
    rating_stars = "⭐" * round(overall_score) + "☆" * (5 - round(overall_score))
    overall_section = f"""
4. Overall Performance
Average Score: {overall_score}/5
Rating: {rating_stars}
"""

    rec_lines = []
    if weak_topics:
        rec_lines.append(f"Improve topics: {', '.join(weak_topics)}.")

    recommendations = f"""
5. Recommendations
Suggested actions: {', '.join(rec_lines) if rec_lines else 'Maintain current performance.'}
"""

    final_report = "\n".join([candidate_details, interview_summary, hr_section, tech_section, overall_section, recommendations])
    print(final_report)

    return {
        "candidate_details": candidate_details,
        "interview_summary": interview_summary,
        "hr_section": hr_section,
        "tech_section": tech_section,
        "overall": overall_section,
        "recommendations": recommendations,
        "evaluation_log": evaluation_log,
        "weak_topics": weak_topics,  # NEW field
        "final_report": final_report
    }
